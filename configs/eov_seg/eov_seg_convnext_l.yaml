_BASE_: ../maskformer2_R50_bs16_90k.yaml
DATASETS:
  TRAIN: ("openvocab_coco_2017_train_panoptic_with_sem_seg",)
  TEST: ("openvocab_ade20k_panoptic_val",) # openvocab_ade20k_panoptic_val, openvocab_ade20k_full_sem_seg_val, openvocab_pascal_ctx59_sem_seg_val, openvocab_pascal_ctx459_sem_seg_val, openvocab_pascal20_sem_seg_val, openvocab_cityscapes_fine_panoptic_val, openvocab_coco_2017_val_panoptic_with_sem_seg,
MODEL:
  BACKBONE:
    NAME: "CLIP"
  WEIGHTS: ""
  EOV_SEG:
    NUM_PROPOSALS: 100
    NUM_STAGES: 3
    AGG_DIM: 96
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: False
      PANOPTIC_ON: True
      OBJECT_MASK_THRESHOLD: 0.0
  OV_HEAD:
    CLIP_MODEL_NAME: "convnext_large_d_320"
    CLIP_PRETRAINED_WEIGHTS: "laion2b_s29b_b131k_ft_soup"
    CLIP_VIT_MODEL_NAME: "ViT-B-16"
    CLIP_VIT_PRETRAINED_WEIGHTS: "openai"
    EMBED_DIM: 768
    ENSEMBLE_ON_VALID_MASK: False
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
OUTPUT_DIR: "output/eov_seg_convnext_l"